{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "reference :\n",
    "\n",
    "https://www.kaggle.com/code/ammarnassanalhajali/uwmgi-unet-keras-inference/notebook\n",
    "\n",
    "\n",
    "kaggle link\n",
    "\n",
    "https://www.kaggle.com/code/ismailazdad/keras-coco-inference2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "! ls ../input/pycocotools",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:13.497882Z",
     "iopub.execute_input": "2022-06-06T13:16:13.498271Z",
     "iopub.status.idle": "2022-06-06T13:16:14.174980Z",
     "shell.execute_reply.started": "2022-06-06T13:16:13.498198Z",
     "shell.execute_reply": "2022-06-06T13:16:14.174047Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install -q pycocotools --no-index --find-links=file:///kaggle/input/pycocotools/ ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:14.177039Z",
     "iopub.execute_input": "2022-06-06T13:16:14.177430Z",
     "iopub.status.idle": "2022-06-06T13:16:26.162451Z",
     "shell.execute_reply.started": "2022-06-06T13:16:14.177389Z",
     "shell.execute_reply": "2022-06-06T13:16:26.161490Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pycocotools\nfrom pycocotools import mask\nimport json\nimport numpy as np\nimport pycocotools.mask as mask_util\nfrom skimage import measure\nimport os\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nimport cv2\nimport random\nfrom itertools import groupby\nimport itertools\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom glob import glob\n# from google.colab.patches import cv2_imshow\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.metrics import *\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.models import load_model",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:26.165712Z",
     "iopub.execute_input": "2022-06-06T13:16:26.166021Z",
     "iopub.status.idle": "2022-06-06T13:16:32.648029Z",
     "shell.execute_reply.started": "2022-06-06T13:16:26.165991Z",
     "shell.execute_reply": "2022-06-06T13:16:32.647193Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n  return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:32.649882Z",
     "iopub.execute_input": "2022-06-06T13:16:32.650389Z",
     "iopub.status.idle": "2022-06-06T13:16:32.664064Z",
     "shell.execute_reply.started": "2022-06-06T13:16:32.650362Z",
     "shell.execute_reply": "2022-06-06T13:16:32.662145Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class FixedDropout(keras.layers.Dropout):\n    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)\n\ncustom_objects = custom_objects={\n    'FixedDropout': FixedDropout,\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    'bce_dice_loss': bce_dice_loss  \n}\n\nmodel = load_model('../input/keras-coco-training/model.h5', custom_objects=custom_objects)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:32.665538Z",
     "iopub.execute_input": "2022-06-06T13:16:32.665912Z",
     "iopub.status.idle": "2022-06-06T13:16:52.853519Z",
     "shell.execute_reply.started": "2022-06-06T13:16:32.665877Z",
     "shell.execute_reply": "2022-06-06T13:16:52.852675Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test_path_json = '../input/keras-coco-training/test_json.json'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:52.859670Z",
     "iopub.execute_input": "2022-06-06T13:16:52.859996Z",
     "iopub.status.idle": "2022-06-06T13:16:52.863932Z",
     "shell.execute_reply.started": "2022-06-06T13:16:52.859969Z",
     "shell.execute_reply": "2022-06-06T13:16:52.862755Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "coco = COCO(test_path_json)\ncatIDs = coco.getCatIds()\nimgIds = coco.getImgIds()\nimgDict = coco.loadImgs(imgIds)\nprint(len(imgIds) , len(catIDs))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:52.865242Z",
     "iopub.execute_input": "2022-06-06T13:16:52.865923Z",
     "iopub.status.idle": "2022-06-06T13:16:53.659098Z",
     "shell.execute_reply.started": "2022-06-06T13:16:52.865752Z",
     "shell.execute_reply": "2022-06-06T13:16:53.658257Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def filterDataset( classes=None, json_file=None):    \n    # initialize COCO api for instance annotations\n    annFile = json_file\n    coco = COCO(annFile)\n    \n    images = []\n    if classes!=None:\n        # iterate for each individual class in the list\n        for className in classes:\n            # get all images containing given categories\n            catIds = coco.getCatIds(catNms=className)\n            imgIds = coco.getImgIds(catIds=catIds)\n            images += coco.loadImgs(imgIds)\n    \n    else:\n        imgIds = coco.getImgIds()\n        images = coco.loadImgs(imgIds)\n    \n    # Now, filter out the repeated images\n    unique_images = []\n    for i in range(len(images)):\n        if images[i] not in unique_images:\n            unique_images.append(images[i])\n            \n    random.shuffle(unique_images)\n    dataset_size = len(unique_images)\n    \n    return unique_images, dataset_size, coco",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:53.660743Z",
     "iopub.execute_input": "2022-06-06T13:16:53.661381Z",
     "iopub.status.idle": "2022-06-06T13:16:53.670495Z",
     "shell.execute_reply.started": "2022-06-06T13:16:53.661339Z",
     "shell.execute_reply": "2022-06-06T13:16:53.669626Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# use image size 128 for better results \nimage_size = 128 \nepochs = 10\nbatch_size = 8\ninput_image_size = (128,128)\nclasses = ['small_bowel', 'large_bowel', 'stomach']",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:53.673258Z",
     "iopub.execute_input": "2022-06-06T13:16:53.673508Z",
     "iopub.status.idle": "2022-06-06T13:16:53.685435Z",
     "shell.execute_reply.started": "2022-06-06T13:16:53.673482Z",
     "shell.execute_reply": "2022-06-06T13:16:53.684457Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "images_test, dataset_size_test, coco_val = filterDataset( classes,  test_path_json)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:53.688983Z",
     "iopub.execute_input": "2022-06-06T13:16:53.689277Z",
     "iopub.status.idle": "2022-06-06T13:16:55.914519Z",
     "shell.execute_reply.started": "2022-06-06T13:16:53.689251Z",
     "shell.execute_reply": "2022-06-06T13:16:55.913718Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class DataGeneratorFromCocoJson(tf.keras.utils.Sequence):\n  # function getting info dataset from json coco\n  # Batch size\n  # subset train or test for annotations\n  # image_list to develop...\n  # classes classe wanted\n  # input image size tuple (X,X)\n  # annFile path to annoted coco json file file\n    def __init__(self, batch_size=batch_size, subset=\"train\", image_list=[], classes=[], input_image_size=(128, 128), annFile='', shuffle=False):\n\n        super().__init__()\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(image_list))\n        self.image_list = image_list\n        self.classes = classes\n        self.input_image_size = (input_image_size)\n        self.dataset_size = len(image_list)\n        self.coco = COCO(annFile)\n        catIds = self.coco.getCatIds(catNms=self.classes)\n        self.catIds = catIds\n        self.cats = self.coco.loadCats(catIDs)\n        self.imgIds = self.coco.getImgIds()\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(len(self.image_list)/self.batch_size)\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def getClassName(self, classID, cats):\n        for i in range(len(cats)):\n            if cats[i]['id'] == classID:\n                return cats[i]['name']\n        return None\n\n    def getNormalMask(self, image_id, catIds):\n        annIds = self.coco.getAnnIds(image_id, catIds=catIds, iscrowd=None)\n        anns = self.coco.loadAnns(annIds)\n        cats = self.coco.loadCats(catIds)\n        train_mask = np.zeros(self.input_image_size, dtype=np.uint8)\n        for a in range(len(anns)):\n            className = self.getClassName(anns[a]['category_id'], cats)\n            pixel_value = self.classes.index(className)+1\n            new_mask = cv2.resize(self.coco.annToMask(\n                anns[a])*pixel_value, self.input_image_size)\n            train_mask = np.maximum(new_mask, train_mask)\n            # train_mask = new_mask / 255.0\n        return train_mask\n\n    def getLevelsMask(self, image_id):\n        # for each category , we get the x mask and add it to mask list\n        res = []\n        mask = np.zeros((self.input_image_size))\n        for j, categorie in enumerate(self.catIds):\n            annIds = coco.getAnnIds(image_id, catIds=categorie, iscrowd=None)\n            anns = coco.loadAnns(annIds)\n            mask = self.getNormalMask(image_id, categorie)\n            res.append(mask)\n        return res\n\n    def getImage(self, file_path):\n        train_img = cv2.imread(file_path, cv2.IMREAD_ANYDEPTH)\n        train_img = cv2.resize(train_img, (self.input_image_size))\n        train_img = train_img.astype(np.float32) / 255.\n        if (len(train_img.shape) == 3 and train_img.shape[2] == 3):\n            return train_img\n        else:\n            stacked_img = np.stack((train_img,)*3, axis=-1)\n            return stacked_img\n\n    def get_image_Infos_by_path_id(self, node):\n        for dict in self.image_list:\n            if dict['file_name'] == node:\n                return dict\n\n    def __getitem__(self, index):\n        X = np.empty((self.batch_size, 128, 128, 3))\n        y = np.empty((self.batch_size, 128, 128, 3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        for i in range(len(indexes)):\n            value = indexes[i]\n            img_info = self.image_list[value]\n            w = img_info['height']\n            h = img_info['width']\n            X[i, ] = self.getImage(img_info['file_name'])\n            mask_train = self.getLevelsMask(img_info['id'])\n            for j in self.catIds:\n                y[i, :, :, j] = mask_train[j]\n                y[i, :, :, j] = mask_train[j]\n                y[i, :, :, j] = mask_train[j]\n\n        X = np.array(X)\n        y = np.array(y)\n\n        if self.subset == 'train':\n            return X, y\n        else:\n            return X",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:55.916018Z",
     "iopub.execute_input": "2022-06-06T13:16:55.916399Z",
     "iopub.status.idle": "2022-06-06T13:16:55.946417Z",
     "shell.execute_reply.started": "2022-06-06T13:16:55.916362Z",
     "shell.execute_reply": "2022-06-06T13:16:55.945617Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test_generator_class = DataGeneratorFromCocoJson(\n    batch_size, \"train\", images_test, classes, input_image_size, test_path_json, shuffle=False)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:55.948667Z",
     "iopub.execute_input": "2022-06-06T13:16:55.949413Z",
     "iopub.status.idle": "2022-06-06T13:16:56.370942Z",
     "shell.execute_reply.started": "2022-06-06T13:16:55.949336Z",
     "shell.execute_reply": "2022-06-06T13:16:56.367961Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "img_s, mask_s = test_generator_class.__getitem__(2)\npreds = model.predict(img_s)\n\n\nfig = plt.figure(figsize=(10, 25))\ngs = gridspec.GridSpec(nrows=len(img_s), ncols=3)\ncolors = ['yellow', 'green', 'red']\nlabels = [\"Small Bowel\", \"Large Bowel\", \"Stomach\"]\npatches = [mpatches.Patch(\n    color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3 = mpl.colors.ListedColormap(colors[2])\nflag = False\nfor i in range(0, 7):\n\n    images, mask = img_s[i], mask_s[i]\n    sample_img = images/255.\n    mask1 = mask[:, :, 0]\n    mask2 = mask[:, :, 1]\n    mask3 = mask[:, :, 2]\n\n    pre = preds[i]\n    predict1 = pre[:, :, 0]\n    predict1 = (predict1 > 0.8).astype(np.float32)\n    predict1 = np.array(predict1)\n    predict2 = pre[:, :, 1]\n    predict3 = pre[:, :, 2]\n\n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img[:, :, 0], cmap='gray')\n\n    ax1 = fig.add_subplot(gs[i, 1])\n    ax2 = fig.add_subplot(gs[i, 2])\n    if(flag == False):\n        flag = True\n        ax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n        ax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n        ax2.set_title(\"predicted Mask\", fontsize=15, weight='bold', y=1.02)\n        plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4, fontsize=14,\n                   title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n    l0 = ax1.imshow(sample_img[:, :, 0], cmap='gray')\n    l1 = ax1.imshow(np.ma.masked_where(\n        mask1 == False,  mask1), cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(\n        mask2 == False,  mask2), cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(\n        mask3 == False,  mask3), cmap=cmap3, alpha=1)\n\n    l0 = ax2.imshow(sample_img[:, :, 0], cmap='gray')\n    l1 = ax2.imshow(np.ma.masked_where(\n        predict1 == False,  predict1), cmap=cmap1, alpha=1)\n    l2 = ax2.imshow(np.ma.masked_where(\n        predict2 == False,  predict2), cmap=cmap2, alpha=1)\n    l3 = ax2.imshow(np.ma.masked_where(\n        predict3 == False,  predict3), cmap=cmap3, alpha=1)\n    _ = [ax.set_axis_off() for ax in [ax0, ax1]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1, l2, l3]]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:16:56.373286Z",
     "iopub.execute_input": "2022-06-06T13:16:56.374027Z",
     "iopub.status.idle": "2022-06-06T13:17:09.396137Z",
     "shell.execute_reply.started": "2022-06-06T13:16:56.373961Z",
     "shell.execute_reply": "2022-06-06T13:17:09.394159Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Run-length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n\n    return ' '.join(str(x) for x in runs)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:17:09.397208Z",
     "iopub.execute_input": "2022-06-06T13:17:09.397606Z",
     "iopub.status.idle": "2022-06-06T13:17:09.405848Z",
     "shell.execute_reply.started": "2022-06-06T13:17:09.397568Z",
     "shell.execute_reply": "2022-06-06T13:17:09.404427Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission_df = pd.DataFrame.from_records(images_test)\nsubmission_df.insert(5, 'prediction', np.nan)\nsubmission_df.insert(3, 'class_name', np.nan)\nsubmission_df.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:17:09.408475Z",
     "iopub.execute_input": "2022-06-06T13:17:09.409275Z",
     "iopub.status.idle": "2022-06-06T13:17:09.472599Z",
     "shell.execute_reply.started": "2022-06-06T13:17:09.409234Z",
     "shell.execute_reply": "2022-06-06T13:17:09.471827Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import gc\ntest_generator_class = DataGeneratorFromCocoJson(\n    1, \"test\", images_test, classes, input_image_size, test_path_json, shuffle = True)\ngc.collect()\nLOGITS = model.predict(test_generator_class, verbose=1)\ngc.collect()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:17:09.473908Z",
     "iopub.execute_input": "2022-06-06T13:17:09.474275Z",
     "iopub.status.idle": "2022-06-06T13:22:06.746294Z",
     "shell.execute_reply.started": "2022-06-06T13:17:09.474237Z",
     "shell.execute_reply": "2022-06-06T13:22:06.745532Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "lbs = []\nsbs = []\nsts = []\nfor index, row in tqdm(submission_df.iterrows(), total=submission_df.shape[0]):\n    root_shape = (submission_df.iloc[index][\"height\"],\n                  submission_df.iloc[index][\"width\"])\n    pred_arr = np.round(cv2.resize(\n        LOGITS[index, :, :, 0], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    sbs.append(rle_encode(pred_arr))\n    pred_arr = np.round(cv2.resize(\n        LOGITS[index, :, :, 1], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    lbs.append(rle_encode(pred_arr))\n    pred_arr = np.round(cv2.resize(\n        LOGITS[index, :, :, 2], root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n    sts.append(rle_encode(pred_arr))\ndel LOGITS\ngc.collect()    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:22:06.747624Z",
     "iopub.execute_input": "2022-06-06T13:22:06.748166Z",
     "iopub.status.idle": "2022-06-06T13:22:20.663694Z",
     "shell.execute_reply.started": "2022-06-06T13:22:06.748126Z",
     "shell.execute_reply": "2022-06-06T13:22:20.662963Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "ids = []\nclasses = []\nrles = []\nfor index, row in tqdm(submission_df.iterrows(), total=submission_df.shape[0]):\n    ids.extend([row['file_id']] * 3)\n    classes.extend(['small_bowel', 'large_bowel', 'stomach'])\n    rles.extend([sbs[index], lbs[index], sts[index]])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:22:20.664889Z",
     "iopub.execute_input": "2022-06-06T13:22:20.665336Z",
     "iopub.status.idle": "2022-06-06T13:22:20.982206Z",
     "shell.execute_reply.started": "2022-06-06T13:22:20.665299Z",
     "shell.execute_reply": "2022-06-06T13:22:20.981417Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission_df = pd.DataFrame()\nsubmission_df['id'] = ids\nsubmission_df['class'] = classes\nsubmission_df['predicted'] = rles\n# submission_df = submission_df.reset_index(drop=True)\nsubmission_df.to_csv(\"submission.csv\", index=False)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:22:20.983479Z",
     "iopub.execute_input": "2022-06-06T13:22:20.984088Z",
     "iopub.status.idle": "2022-06-06T13:22:21.385906Z",
     "shell.execute_reply.started": "2022-06-06T13:22:20.984047Z",
     "shell.execute_reply": "2022-06-06T13:22:21.385066Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission_df.sample(10)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-06T13:22:21.387163Z",
     "iopub.execute_input": "2022-06-06T13:22:21.387516Z",
     "iopub.status.idle": "2022-06-06T13:22:21.405079Z",
     "shell.execute_reply.started": "2022-06-06T13:22:21.387480Z",
     "shell.execute_reply": "2022-06-06T13:22:21.404353Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  }
 ]
}